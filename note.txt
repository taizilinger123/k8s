###################################################
[root@node-2 k8s]# cat gitPush.sh 
#!/bin/bash 
DATE=`date +%Y%m%d`
git  add .
git commit -m  "$DATE"
git  push  git@github.com:taizilinger123/k8s.git 
##################################################
kubectl create deployment nginx --image=nginx
kubectl   get   pod   -A  -o  wide
kubectl   get  pod
kubectl  get  deployments.apps
[root@node-1 ~]# kubectl  get  deployments.apps 
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   1/1     1            1           45h
[root@node-1 ~]# kubectl  get  replicasets.apps 
NAME               DESIRED   CURRENT   READY   AGE
nginx-86c57db685   1         1         1       45h
[root@node-1 ~]# kubectl  get  rs 
NAME               DESIRED   CURRENT   READY   AGE
nginx-86c57db685   1         1         1       45h
[root@node-1 ~]# kubectl  scale -h 
Examples:
  # Scale a replicaset named 'foo' to 3.
  kubectl scale --replicas=3 rs/foo
[root@node-1 ~]# kubectl  scale deployment nginx  --replicas=2
deployment.apps/nginx scaled
[root@node-1 ~]# kubectl  get  pod 
NAME                     READY   STATUS    RESTARTS   AGE
nginx-86c57db685-mx59g   1/1     Running   0          11m
nginx-86c57db685-r67fx   1/1     Running   0          65s
[root@node-1 ~]# kubectl  get deployments.apps 
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   2/2     2            2           45h
[root@node-1 ~]# kubectl  get  pod  -o  wide 
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE     NOMINATED NODE   READINESS GATES
nginx-86c57db685-mx59g   1/1     Running   0          11m   10.244.1.10   node-2   <none>           <none>
nginx-86c57db685-r67fx   1/1     Running   0          98s   10.244.2.17   node-3   <none>           <none>
[root@node-1 ~]# kubectl  set  image deployment/nginx nginx=nginx:1.19.7 --record
deployment.apps/nginx image updated
[root@node-1 ~]# kubectl   get  pod -w     #监控节点创建过程
NAME                     READY   STATUS              RESTARTS   AGE
nginx-5cf4d8f79-2cmgx    0/1     ContainerCreating   0          37s
nginx-86c57db685-mx59g   1/1     Running             0          16m
nginx-86c57db685-r67fx   1/1     Running             0          6m47s
[root@node-1 ~]# kubectl   get  pod  -o  wide 
NAME                     READY   STATUS              RESTARTS   AGE     IP            NODE     NOMINATED NODE   READINESS GATES
nginx-5cf4d8f79-2cmgx    1/1     Running             0          2m5s    10.244.1.11   node-2   <none>           <none>
nginx-5cf4d8f79-vdh52    0/1     ContainerCreating   0          19s     <none>        node-3   <none>           <none>
nginx-86c57db685-r67fx   1/1     Running             0          8m15s   10.244.2.17   node-3   <none>           <none>
[root@node-1 ~]# curl  10.244.1.11
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
[root@node-1 ~]# curl  10.244.1.11/1
<html>
<head><title>404 Not Found</title></head>
<body>
<center><h1>404 Not Found</h1></center>
<hr><center>nginx/1.19.7</center>   ####这里能看到nginx镜像版本
</body>
</html>
[root@node-1 ~]# kubectl  describe deployments.apps  nginx 
OldReplicaSets:  <none>
NewReplicaSet:   nginx-5cf4d8f79 (2/2 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  59m   deployment-controller  Scaled up replica set nginx-86c57db685 to 2
  Normal  ScalingReplicaSet  53m   deployment-controller  Scaled up replica set nginx-5cf4d8f79 to 1
  Normal  ScalingReplicaSet  51m   deployment-controller  Scaled down replica set nginx-86c57db685 to 1
  Normal  ScalingReplicaSet  51m   deployment-controller  Scaled up replica set nginx-5cf4d8f79 to 2
  Normal  ScalingReplicaSet  50m   deployment-controller  Scaled down replica set nginx-86c57db685 to 0
[root@node-1 ~]# kubectl  rollout  history deployment  nginx 
deployment.apps/nginx 
REVISION  CHANGE-CAUSE
1         <none>
2         kubectl set image deployment/nginx nginx=nginx:1.19.7 --record=true
[root@node-1 ~]# kubectl  set  image deployment/nginx nginx=nginx:1.19.1 --record
deployment.apps/nginx image updated
[root@node-1 ~]# kubectl   get  pod   -w
NAME                     READY   STATUS              RESTARTS   AGE
nginx-5cf4d8f79-2cmgx    1/1     Running             0          62m
nginx-5cf4d8f79-vdh52    1/1     Running             0          60m
nginx-5dd4b6cddf-qxml2   0/1     ContainerCreating   0          8s
[root@node-1 ~]# kubectl  rollout  history deployment  nginx 
deployment.apps/nginx 
REVISION  CHANGE-CAUSE
1         <none>
2         kubectl set image deployment/nginx nginx=nginx:1.19.7 --record=true
3         kubectl set image deployment/nginx nginx=nginx:1.19.1 --record=true
[root@node-1 ~]# curl  10.244.2.19/1
<html>
<head><title>404 Not Found</title></head>
<body>
<center><h1>404 Not Found</h1></center>
<hr><center>nginx/1.19.1</center>   #这里看nginx的版本是1.19.1
</body>
</html>
[root@node-1 ~]# kubectl  rollout  history deployment  nginx 
deployment.apps/nginx 
REVISION  CHANGE-CAUSE
1         <none>
2         kubectl set image deployment/nginx nginx=nginx:1.19.7 --record=true     #看前面的数字2 revision
3         kubectl set image deployment/nginx nginx=nginx:1.19.1 --record=true  
[root@node-1 ~]# kubectl  rollout undo  deployment nginx  --to-revision=2
deployment.apps/nginx rolled back
[root@node-1 ~]# kubectl   get  pod  -w
NAME                     READY   STATUS              RESTARTS   AGE
nginx-5cf4d8f79-v4jhf    0/1     ContainerCreating   0          2s
nginx-5cf4d8f79-v87ps    1/1     Running             0          20s
nginx-5dd4b6cddf-969n6   1/1     Running             0          7m11s
nginx-5dd4b6cddf-qxml2   1/1     Terminating         0          8m33s
nginx-5dd4b6cddf-qxml2   0/1     Terminating         0          8m34s
nginx-5dd4b6cddf-qxml2   0/1     Terminating         0          8m35s
nginx-5dd4b6cddf-qxml2   0/1     Terminating         0          8m35s
nginx-5cf4d8f79-v4jhf    1/1     Running             0          20s
nginx-5dd4b6cddf-969n6   1/1     Terminating         0          7m30s
nginx-5dd4b6cddf-969n6   0/1     Terminating         0          7m32s
nginx-5dd4b6cddf-969n6   0/1     Terminating         0          7m33s
nginx-5dd4b6cddf-969n6   0/1     Terminating         0          7m33s
[root@node-1 ~]# kubectl   get  pod   -o wide 
NAME                    READY   STATUS    RESTARTS   AGE     IP            NODE     NOMINATED NODE   READINESS GATES
nginx-5cf4d8f79-v4jhf   1/1     Running   0          4m8s    10.244.2.20   node-3   <none>           <none>
nginx-5cf4d8f79-v87ps   1/1     Running   0          4m26s   10.244.1.13   node-2   <none>           <none>
[root@node-1 ~]# curl  10.244.2.20/1
<html>
<head><title>404 Not Found</title></head>
<body>
<center><h1>404 Not Found</h1></center>
<hr><center>nginx/1.19.7</center>  #这里看nginx版本改为1.19.7了就是之前的版本
</body>
</html>
[root@node-1 ~]# kubectl  rollout  history deployment  nginx 
deployment.apps/nginx 
REVISION  CHANGE-CAUSE
1         <none>
3         kubectl set image deployment/nginx nginx=nginx:1.19.1 --record=true
4         kubectl set image deployment/nginx nginx=nginx:1.19.7 --record=true
[root@node-1 ~]# kubectl  get  node 
NAME     STATUS   ROLES    AGE   VERSION
node-1   Ready    master   47h   v1.17.0
node-2   Ready    worker   47h   v1.17.0
node-3   Ready    worker   47h   v1.17.0
[root@node-1 ~]# kubectl  cordon node-1      #打个污点
node/node-1 cordoned
[root@node-1 ~]# 
[root@node-1 ~]# kubectl  get  node 
NAME     STATUS                     ROLES    AGE   VERSION
node-1   Ready,SchedulingDisabled   master   47h   v1.17.0
node-2   Ready                      worker   47h   v1.17.0
node-3   Ready                      worker   47h   v1.17.0
[root@node-1 ~]# kubectl  cordon node-2
node/node-2 cordoned
[root@node-1 ~]# kubectl  get  node 
NAME     STATUS                     ROLES    AGE   VERSION
node-1   Ready,SchedulingDisabled   master   47h   v1.17.0
node-2   Ready,SchedulingDisabled   worker   47h   v1.17.0
node-3   Ready                      worker   47h   v1.17.0
[root@node-1 ~]# kubectl  drain  -h
[root@node-1 ~]# kubectl  drain  node-2 --ignore-daemonsets --force  --delete-local-data 
node/node-2 already cordoned
evicting pod "metrics-server-6589f84c7-xq8bq"
pod/metrics-server-6589f84c7-xq8bq evicted
node/node-2 evicted
[root@node-1 ~]# kubectl  get  pod  -o wide 
NAME                    READY   STATUS    RESTARTS   AGE     IP            NODE     NOMINATED NODE   READINESS GATES
nginx-5cf4d8f79-v4jhf   1/1     Running   0          45m     10.244.2.20   node-3   <none>           <none>
nginx-5cf4d8f79-ztnz7   1/1     Running   0          5m42s   10.244.2.21   node-3   <none>           <none>             #可以看到都在node-3这个节点上了，打了污点和驱逐node-2
[root@node-1 ~]# kubectl  get  node 
NAME     STATUS                     ROLES    AGE   VERSION
node-1   Ready,SchedulingDisabled   master   47h   v1.17.0
node-2   Ready,SchedulingDisabled   worker   47h   v1.17.0
node-3   Ready                      worker   47h   v1.17.0
[root@node-1 ~]# kubectl  uncordon node-2            #去除打的污点
node/node-2 uncordoned
[root@node-1 ~]# kubectl  get  node 
NAME     STATUS                     ROLES    AGE   VERSION
node-1   Ready,SchedulingDisabled   master   47h   v1.17.0
node-2   Ready                      worker   47h   v1.17.0
node-3   Ready                      worker   47h   v1.17.0
[root@node-1 ~]# kubectl  create deployment nginx --image=nginx --dry-run -o yaml    #yaml文件编写格式生成
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: nginx
  name: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx
        name: nginx
        resources: {}
status: {}
[root@node-1 ~]# kubectl  create deployment nginx --image=nginx --dry-run -o yaml > nginx.yaml 
[root@node-1 ~]# cat  nginx.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: nginx
  name: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx
        name: nginx
        resources: {}
status: {}
[root@node-1 ~]# kubectl  delete  deployment  nginx 
deployment.apps "nginx" deleted
[root@node-1 ~]# kubectl  get  rs
No resources found in default namespace.
[root@node-1 ~]# kubectl  get   pod 
No resources found in default namespace.
[root@node-1 ~]# kubectl  get  deployments.apps 
No resources found in default namespace.
##########################################################
[root@node-1 k8s.yaml]# cat  nginx.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: nginx
  name: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx
        name: nginx
        resources: {}
status: {}
[root@node-1 k8s.yaml]# kubectl  apply  -f  nginx.yaml  --record
deployment.apps/nginx created
[root@node-1 k8s.yaml]# kubectl  get  deployments.apps 
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   2/2     2            2           36s
[root@node-1 k8s.yaml]# kubectl  get  rs
NAME               DESIRED   CURRENT   READY   AGE
nginx-86c57db685   2         2         2       41s
[root@node-1 k8s.yaml]# kubectl  get   pod -o  wide 
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE     NOMINATED NODE   READINESS GATES
nginx-86c57db685-grqft   1/1     Running   0          46s   10.244.2.22   node-3   <none>           <none>
nginx-86c57db685-vv7jm   1/1     Running   0          46s   10.244.1.14   node-2   <none>           <none>
############################################################################
[root@node-1 k8s.yaml]# kubectl run  busybox --image=busybox --dry-run=client -o yaml > testHealthz.yaml 
Error: invalid argument "client" for "--dry-run" flag: strconv.ParseBool: parsing "client": invalid syntax
See 'kubectl run --help' for usage.
[root@node-1 k8s.yaml]# kubectl run  busybox --image=busybox --dry-run=1 -o yaml > testHealthz.yaml 
kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.
[root@node-1 k8s.yaml]# cat   testHealthz.yaml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: busybox
  name: busybox
spec:
  containers:
  - image: busybox
    name: busybox
    resources: {}
    args:
    - /bin/sh
    - -c
    - sleep 10; exit 1       # 并添加pod运行指定脚本命令，模拟容器启动10秒后发生故障，退出状态码为1
  dnsPolicy: ClusterFirst
  restartPolicy: OnFailure # 将默认的Always修改为OnFailure
status: {}
[root@node-1 k8s.yaml]# kubectl apply  -f  testHealthz.yaml 
pod/busybox created
[root@node-1 k8s.yaml]# kubectl  get  pod 
NAME                     READY   STATUS              RESTARTS   AGE
busybox                  0/1     ContainerCreating   0          11s
nginx-86c57db685-grqft   1/1     Running             0          31m
nginx-86c57db685-vv7jm   1/1     Running             0          31m
[root@node-1 k8s.yaml]# kubectl  describe  pod  busybox
[root@node-1 k8s.yaml]# kubectl  get  pod  -w 
NAME                     READY   STATUS             RESTARTS   AGE
busybox                  0/1     CrashLoopBackOff   3          3m16s
nginx-86c57db685-grqft   1/1     Running            0          34m
nginx-86c57db685-vv7jm   1/1     Running            0          34m
busybox                  1/1     Running            4          3m49s
busybox                  0/1     Error              4          4m1s
busybox                  0/1     CrashLoopBackOff   4          4m13s
busybox                  1/1     Running            5          5m29s
busybox                  0/1     Error              5          5m41s
busybox                  0/1     CrashLoopBackOff   5          5m54s
[root@node-1 k8s.yaml]# kubectl  delete -f  testHealthz.yaml 
pod "busybox" deleted
[root@node-1 k8s.yaml]# cat   liveness.yaml 
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness
spec:
  restartPolicy: OnFailure
  containers:
  - name: liveness
    image: busybox
    args:
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 10   # 容器启动 10 秒之后开始检测
      periodSeconds: 5          # 每隔 5 秒再检测一次
[root@node-1 k8s.yaml]# kubectl  apply  -f  liveness.yaml 
[root@node-1 k8s.yaml]# kubectl get pod   -w
NAME                     READY   STATUS    RESTARTS   AGE
liveness                 1/1     Running   0          88s
nginx-86c57db685-grqft   1/1     Running   0          45m
nginx-86c57db685-vv7jm   1/1     Running   0          45m
liveness                 1/1     Running   1          93s
liveness                 1/1     Running   2          3m5s    #restarts 服务不正常重启了几次
[root@node-1 k8s.yaml]# kubectl  describe  pod liveness
Events:
  Type     Reason     Age                  From               Message
  ----     ------     ----                 ----               -------
  Normal   Scheduled  4m15s                default-scheduler  Successfully assigned default/liveness to node-2
  Normal   Pulling    88s (x3 over 4m13s)  kubelet, node-2    Pulling image "busybox"
  Normal   Pulled     72s (x3 over 3m57s)  kubelet, node-2    Successfully pulled image "busybox"
  Normal   Created    72s (x3 over 3m57s)  kubelet, node-2    Created container liveness
  Normal   Started    71s (x3 over 3m56s)  kubelet, node-2    Started container liveness
  Warning  Unhealthy  29s (x9 over 3m24s)  kubelet, node-2    Liveness probe failed: cat: can't open '/tmp/healthy': No such file or directory
  Normal   Killing    29s (x3 over 3m14s)  kubelet, node-2    Container liveness failed liveness probe, will be restarted
[root@node-1 k8s.yaml]# cat  readiness.yaml 
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness
spec:
  restartPolicy: OnFailure
  containers:
  - name: liveness
    image: busybox
    args:
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600
    readinessProbe:    # 这里将livenessProbe换成readinessProbe即可，其它配置都一样
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 10   # 容器启动 10 秒之后开始检测
      periodSeconds: 5          # 每隔 5 秒再检测一次
[root@node-1 k8s.yaml]# kubectl  apply    -f  readiness.yaml 
[root@node-1 k8s.yaml]# cat  myapp-v1.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mytest
spec:
  replicas: 10     # 这里准备10个数量的pod
  selector:
    matchLabels:
      app: mytest
  template:
    metadata:
      labels:
        app: mytest
    spec:
      containers:
      - name: mytest
        image: busybox
        args:
        - /bin/sh
        - -c
        - sleep 10; touch /tmp/healthy; sleep 30000
        readinessProbe:
          exec:
            command:
            - cat
            - /tmp/healthy
          initialDelaySeconds: 10
          periodSeconds: 5
[root@node-1 k8s.yaml]# kubectl  apply  -f   myapp-v1.yaml
[root@node-1 k8s.yaml]# cat  myapp-v2.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mytest
spec:
  strategy:
    rollingUpdate:
      maxSurge: 35%   # 滚动更新的副本总数最大值(以10的基数为例)：10 + 10 * 35% = 13.5 --> 14
      maxUnavailable: 35%  # 可用副本数最大值(默认值两个都是25%)： 10 - 10 * 35% = 6.5  --> 7
  replicas: 10
  selector:
    matchLabels:
      app: mytest
  template:
    metadata:
      labels:
        app: mytest
    spec:
      containers:
      - name: mytest
        image: busybox
        args:
        - /bin/sh
        - -c
        - sleep 30000   # 可见这里并没有生成/tmp/healthy这个文件，所以下面的检测必然失败
        readinessProbe:
          exec:
            command:
            - cat
            - /tmp/healthy
          initialDelaySeconds: 10
          periodSeconds: 5
[root@node-1 k8s.yaml]# kubectl   apply  -f  myapp-v2.yaml   --record 
deployment.apps/mytest configured
[root@node-1 k8s.yaml]# kubectl   rollout  history  deployment   mytest
deployment.apps/mytest 
REVISION  CHANGE-CAUSE
1         <none>
2         kubectl apply --filename=myapp-v2.yaml --record=true
[root@node-1 k8s.yaml]# kubectl  get   deployments.apps   mytest
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
mytest   7/10    7            7           9m13s
[root@node-1 k8s.yaml]# kubectl  describe   deployments.apps mytest 
[root@node-1 k8s.yaml]# kubectl  get   deployments.apps 
mytest  nginx   
[root@node-1 k8s.yaml]# kubectl  get   deployments.apps mytest 
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
mytest   7/10    7            7           11m
[root@node-1 k8s.yaml]# kubectl  edit    deployments.apps mytest 
Edit cancelled, no changes made.
  strategy:
    rollingUpdate:
      maxSurge: 35%
      maxUnavailable: 35%
    type: RollingUpdate
